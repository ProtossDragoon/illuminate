1
00:00:00,000 --> 00:00:04,950
우리는 세계관을 담아낼 수 있을겁니다.
We can capture the underlying worldview

2
00:00:04,950 --> 00:00:07,580
아리스토텔레스의 세계관을요.
of Aristotle

3
00:00:07,580 --> 00:00:09,440
컴퓨터에 말입니다.
in a computer.

4
00:00:09,440 --> 00:00:12,560
그리고 언젠간, 몇몇 학생들은
And someday, some student will be able

5
00:00:12,560 --> 00:00:14,720
아리스토텔레스가 쓴 글을 읽는 것을 넘어서
not only to read the words Aristotle

6
00:00:14,720 --> 00:00:17,180
아리스토텔레스에게 질문을 던지게 될 겁니다.
but ask Aristotle a question.

7
00:00:18,940 --> 00:00:19,760
우리들의 문제를

8
00:00:19,760 --> 00:00:21,610
IT로 해결한다, 솔브잇입니다.

9
00:00:21,610 --> 00:00:23,410
여러분 주식 하나쯤 들고 계시죠

10
00:00:23,410 --> 00:00:25,760
혹시 이런 상상 해 본 적 있으신가요?

11
00:00:25,760 --> 00:00:27,670
"레이 달리오나 워런 버핏이라면,

12
00:00:27,670 --> 00:00:29,090
이 주식을 팔지 않고,

13
00:00:29,090 --> 00:00:31,310
존버를 할까?" 같은 상상 말이에요.

14
00:00:31,310 --> 00:00:32,450
여러분만 하는 상상은

15
00:00:32,450 --> 00:00:33,390
아닌 것 같습니다.

16
00:00:33,390 --> 00:00:35,760
스티브 잡스는 여러 매체를 통해

17
00:00:35,760 --> 00:00:38,010
아리스토텔레스나 소크라테스와

18
00:00:38,010 --> 00:00:40,530
대화를 나누고 싶다는 이야기를 남겼습니다.

19
00:00:40,530 --> 00:00:42,460
스티브 잡스도 그런 생각을 한거죠.

20
00:00:42,460 --> 00:00:44,680
"아... 테스 형님은 이 문제에 대해

21
00:00:44,680 --> 00:00:45,950
어떻게 생각하실까?"

22
00:00:45,950 --> 00:00:47,850
인문학 책을 정말 많이 읽었던

23
00:00:47,850 --> 00:00:49,160
스티브 잡스마저도,

24
00:00:49,160 --> 00:00:50,200
직접 대화를 나누며

25
00:00:50,200 --> 00:00:52,260
통찰을 얻고 싶었을 것입니다.

26
00:00:52,260 --> 00:00:53,830
저도 그런 적이 많았습니다.

27
00:00:53,830 --> 00:00:56,060
저는 몇 번의 스타트업이나 프로젝트들에

28
00:00:56,060 --> 00:00:58,470
도전했다가 실패한 적이 많은데요.

29
00:00:58,470 --> 00:01:01,260
뒤늦게 돌이켜보니 과거의 창업 선배들이

30
00:01:01,260 --> 00:01:03,850
책을 통해 계속 경고하던 부분이더군요.

31
00:01:03,850 --> 00:01:06,660
심지어 창업 멘토들의 책을 읽었음에도,

32
00:01:06,660 --> 00:01:08,130
저는 제 프로젝트에

33
00:01:08,130 --> 00:01:10,290
그 통찰을 반영하지 못했습니다.

34
00:01:10,290 --> 00:01:11,870
만약 제 프로젝트에 대해

35
00:01:11,870 --> 00:01:14,540
창업 멘토들에게 컨설팅을 받았다면,

36
00:01:14,540 --> 00:01:16,980
결과가 조금은 달라지지 않았을까요?

37
00:01:16,980 --> 00:01:19,700
자신이 존경하는 사람과 이야기를 나누는 것.

38
00:01:19,700 --> 00:01:21,350
모두가 중요하게 생각하고,

39
00:01:21,350 --> 00:01:24,110
스티브 잡스가 그토록 원하던 것이기도 합니다.

40
00:01:24,110 --> 00:01:27,730
이제 거대언어모델과 인공지능 기술을 이용해서,

41
00:01:27,730 --> 00:01:29,670
나만을 위한 아리스토텔레스,

42
00:01:29,670 --> 00:01:31,360
나만을 위한 일론 머스크,

43
00:01:31,360 --> 00:01:33,370
나만을 위한 워런 버핏을 만들어볼

44
00:01:33,370 --> 00:01:34,670
기회가 생겼습니다.

45
00:01:34,670 --> 00:01:36,720
그런데 당연히 단순히 언어모델을

46
00:01:36,720 --> 00:01:38,530
사용한다고 기적적인 결과를

47
00:01:38,530 --> 00:01:40,010
기대하기는 어렵습니다.

48
00:01:40,010 --> 00:01:41,420
우리가 언어모델을 통해

49
00:01:41,420 --> 00:01:43,410
가상의 멘토들을 만들었을 때,

50
00:01:43,410 --> 00:01:45,970
어떤 의미가 생기는지 고민이 필요합니다.

51
00:01:45,970 --> 00:01:48,360
저 나름의 언어로 정의를 해 보았는데요,

52
00:01:48,360 --> 00:01:49,910
여러분도 공감하시는지

53
00:01:49,910 --> 00:01:52,110
한번 생각해 보면 좋을 것 같습니다.

54
00:01:52,110 --> 00:01:54,050
우리가 어떻게 정보를 습득하는지

55
00:01:54,050 --> 00:01:55,930
정말 단순하게 생각해 봅시다.

56
00:01:55,930 --> 00:01:57,350
어떤 정보가 있습니다.

57
00:01:57,350 --> 00:01:58,330
그리고 우리는,

58
00:01:58,330 --> 00:02:00,830
그 정보를 이해해서 흡수합니다.

59
00:02:00,830 --> 00:02:03,840
여기서 정보란, 신문 기사가 될 수도 있고,

60
00:02:03,840 --> 00:02:05,160
영화가 될 수도 있고,

61
00:02:05,160 --> 00:02:06,410
책이 될 수도 있고,

62
00:02:06,410 --> 00:02:07,850
솔브잇의 유튜브 컨텐츠가

63
00:02:07,850 --> 00:02:09,010
될 수도 있습니다.

64
00:02:09,010 --> 00:02:10,620
우리는 그런 컨텐츠를 읽거나,

65
00:02:10,620 --> 00:02:12,450
보거나, 들으면서

66
00:02:12,450 --> 00:02:14,910
이해하고 흡수하기 위해 노력하죠.

67
00:02:14,910 --> 00:02:17,210
그런데 여기서 아주 중요한 뭔가,

68
00:02:17,210 --> 00:02:18,640
하나가 빠져 있습니다.

69
00:02:18,640 --> 00:02:20,560
오늘 컨텐츠의 주제이기도 한데요.

70
00:02:20,560 --> 00:02:22,510
바로, 해석이라는 단계입니다.

71
00:02:22,510 --> 00:02:24,730
이해와 해석은 비슷한 단어 같은데요,

72
00:02:24,730 --> 00:02:26,480
그럼에도 불구하고 이것을

73
00:02:26,480 --> 00:02:27,870
주의깊게 다루는 이유는,

74
00:02:27,870 --> 00:02:30,750
우리가 이번에 언어모델에게 기대하는 바가,

75
00:02:30,750 --> 00:02:32,800
이해가 아니라 해석이기 때문입니다.

76
00:02:32,800 --> 00:02:34,440
예시를 몇 가지 들어 봅시다.

77
00:02:34,440 --> 00:02:35,690
우리가 영화를 보면

78
00:02:35,690 --> 00:02:37,690
얼추 내용이 이해가 되긴 합니다.

79
00:02:37,690 --> 00:02:39,660
하지만 이동진 평론가나

80
00:02:39,660 --> 00:02:41,610
박평식 평론가의 시각을 통해

81
00:02:41,610 --> 00:02:43,010
영화를 다시 바라보면

82
00:02:43,010 --> 00:02:44,960
새로운 인사이트를 얻었던 것 같아요.

83
00:02:44,960 --> 00:02:47,870
그들의 해석을 통해 우리가 미처 보지 못한

84
00:02:47,870 --> 00:02:49,400
영화의 깊은 의미나

85
00:02:49,400 --> 00:02:51,610
감독의 의도를 발견하게 되죠.

86
00:02:51,610 --> 00:02:52,820
경제뉴스와 주가 정보를

87
00:02:52,820 --> 00:02:54,340
모두 이해한다고 해도,

88
00:02:54,340 --> 00:02:56,350
워런 버핏이나 레이 달리오 같은

89
00:02:56,350 --> 00:02:58,600
투자자의 관점에서 그 둘의 관계를

90
00:02:58,600 --> 00:03:00,880
해석하는 것은 또 다른 이야기입니다.

91
00:03:00,880 --> 00:03:02,220
우리는 뉴스의 내용과

92
00:03:02,220 --> 00:03:04,060
주가의 변동을 이해하지만,

93
00:03:04,060 --> 00:03:05,940
그 둘 사이의 미묘한 관계나

94
00:03:05,940 --> 00:03:08,210
미래의 투자 전략을 파악하는 데에는

95
00:03:08,210 --> 00:03:10,240
그들의 통찰이 큰 도움이 됩니다.

96
00:03:10,240 --> 00:03:13,070
많은 분들이 정보를 단순히 이해하기 위해

97
00:03:13,070 --> 00:03:15,340
거대 언어 모델을 사용하고 있습니다.

98
00:03:15,340 --> 00:03:17,220
예를 들어, GPT한테

99
00:03:17,220 --> 00:03:19,270
"블록체인이 뭔지 알려줘"라고

100
00:03:19,270 --> 00:03:20,390
물어보는 식이죠.

101
00:03:20,390 --> 00:03:21,710
하지만 우리는,

102
00:03:21,710 --> 00:03:23,450
정보를 해석하는 도구로써

103
00:03:23,450 --> 00:03:25,340
언어모델을 활용하고자 합니다.

104
00:03:25,340 --> 00:03:27,950
즉, 우리가 직접 만날 수 없는 멘토를

105
00:03:27,950 --> 00:03:30,480
언어 모델로 구현했을 때 기대하는 것은

106
00:03:30,480 --> 00:03:33,450
바로, '내가 보고 있는 영화' 라던가,

107
00:03:33,450 --> 00:03:35,360
'우리가 하려는 프로젝트' 라던가,

108
00:03:35,360 --> 00:03:36,910
'우리가 가지고 있는 주식'에 대한

109
00:03:36,910 --> 00:03:37,740
해석입니다.

110
00:03:37,740 --> 00:03:39,440
우리가 이번에 만들 서비스는,

111
00:03:39,440 --> 00:03:42,070
우리만의 관점으로 정보를 이해하지 않고,

112
00:03:42,070 --> 00:03:45,390
타인의 관점으로 정보를 이해한 결과물인

113
00:03:45,390 --> 00:03:47,690
'해석'을 생성하는 서비스입니다.

114
00:03:47,690 --> 00:03:49,340
그럼 더욱 풍부하게 정보를

115
00:03:49,340 --> 00:03:51,230
이해할 가능성이 생길 테니까요.

116
00:03:51,230 --> 00:03:53,210
비디오의 흐름을 이해하는 데

117
00:03:53,210 --> 00:03:54,280
집중해 주세요.

118
00:03:54,280 --> 00:03:56,140
디테일은 빠르게 넘어갑니다!

119
00:03:56,140 --> 00:03:58,570
대신 자세한 내용을 댓글이나 설명란에

120
00:03:58,570 --> 00:04:00,750
제공해 드릴 테니, 걱정하지 마세요.

121
00:04:00,750 --> 00:04:01,950
자, 그럼 시작해봅시다!

122
00:04:01,950 --> 00:04:03,660
다음과 같은 단계들로

123
00:04:03,660 --> 00:04:05,650
프로그램을 완성해 보려고 합니다.

124
00:04:05,650 --> 00:04:07,040
우선 Step A에서는

125
00:04:07,040 --> 00:04:09,080
지난번에 만들었던 '찾았다'라는

126
00:04:09,080 --> 00:04:11,240
서비스를 조금 손볼 것입니다.

127
00:04:11,240 --> 00:04:12,570
그리고 Step B에서는

128
00:04:12,570 --> 00:04:14,170
내가 본받고 싶은 점이 있는

129
00:04:14,170 --> 00:04:16,350
멘토가 새로운 해석을 제시하도록

130
00:04:16,350 --> 00:04:17,640
만들어 볼 것입니다.

131
00:04:17,640 --> 00:04:19,190
'찾았다'는, 내가 좋아하는

132
00:04:19,190 --> 00:04:21,280
콘텐츠 제작자의 새로운 콘텐츠가

133
00:04:21,280 --> 00:04:23,340
올라오는 경우, 콘텐츠가 나의

134
00:04:23,340 --> 00:04:25,330
관심 주제와 맞는지 확인한 뒤

135
00:04:25,330 --> 00:04:27,520
링크를 보내주는 시스템입니다.

136
00:04:27,520 --> 00:04:29,330
이것을 통해, 나의 관심사에

137
00:04:29,330 --> 00:04:31,650
부합하는 고품질 콘텐츠를

138
00:04:31,650 --> 00:04:33,710
디스코드나 이메일같이 내가

139
00:04:33,710 --> 00:04:36,050
선호하는 채널로 받아볼 수 있게 되었습니다.

140
00:04:36,050 --> 00:04:37,660
아까 우리가 효과적인 정보 처리

141
00:04:37,660 --> 00:04:39,330
과정이라고 생각했던 것을

142
00:04:39,330 --> 00:04:41,320
다시 떠올려 보면, 어떤 정보가

143
00:04:41,320 --> 00:04:42,960
있고, 그 정보에 대한 다양한

144
00:04:42,960 --> 00:04:45,000
해석을 멘토로부터 제시받고,

145
00:04:45,000 --> 00:04:48,000
해석과 함께 정보를 이해한다고 했습니다.

146
00:04:48,000 --> 00:04:49,800
하지만 지금까지 만들었던

147
00:04:49,800 --> 00:04:52,040
'찾았다' 서비스는, 단순히

148
00:04:52,040 --> 00:04:54,160
원문 링크를 보내주기만 할 뿐입니다.

149
00:04:54,160 --> 00:04:55,960
즉, 정보만 있을 뿐,

150
00:04:55,960 --> 00:04:58,160
별도의 해석이 존재하지 않습니다.

151
00:04:58,160 --> 00:05:00,410
그래서 우리는, 우리의 관점으로만

152
00:05:00,410 --> 00:05:02,010
정보를 이해해야 했습니다.

153
00:05:02,010 --> 00:05:02,930
Step B에서 우리가

154
00:05:02,930 --> 00:05:04,880
멘토의 해석을 생성할 것이므로,

155
00:05:04,880 --> 00:05:06,560
Step A에서는 멘토님이

156
00:05:06,560 --> 00:05:08,320
콘텐츠를 읽을 수 있는 형태로

157
00:05:08,320 --> 00:05:09,700
준비해 두는 것입니다.

158
00:05:09,700 --> 00:05:12,400
그런데 멘토가 한 명뿐이라는 법은 없습니다.

159
00:05:12,400 --> 00:05:14,270
각 정보마다, 정보를 더 잘

160
00:05:14,270 --> 00:05:15,610
해석해 줄 수 있는 멘토는

161
00:05:15,610 --> 00:05:16,810
다를 것이기 때문에,

162
00:05:16,810 --> 00:05:18,990
적절한 멘토를 Step C에서는

163
00:05:18,990 --> 00:05:20,820
한 명이 아닌 여러 명의 멘토

164
00:05:20,820 --> 00:05:23,140
중에서 선택하여 해석을 받아볼 수

165
00:05:23,140 --> 00:05:25,540
있도록 시스템을 확장해 보겠습니다.

166
00:05:25,540 --> 00:05:27,440
마지막으로 Step D에서는

167
00:05:27,440 --> 00:05:28,950
다른 사람의 해석이 아닌,

168
00:05:28,950 --> 00:05:30,970
나만의 해석을 만들어 보겠습니다.

169
00:05:30,970 --> 00:05:33,110
제가 작성한 문서들을 입력하고,

170
00:05:33,110 --> 00:05:35,800
그 내용을 바탕으로 해석하도록 하는 것입니다.

171
00:05:35,800 --> 00:05:37,680
지금까지 우리가 살아오면서 쌓은

172
00:05:37,680 --> 00:05:39,990
경험을 적극 활용할 줄 안다는 것은

173
00:05:39,990 --> 00:05:42,170
우리에게 강력한 무기가 되기 때문입니다.

174
00:05:42,170 --> 00:05:44,100
먼저, 화면에 보이는 것은

175
00:05:44,100 --> 00:05:46,440
우리가 이전에 만들었던 워크플로우입니다.

176
00:05:46,440 --> 00:05:48,350
이 워크플로우는 우리가 좋아하는

177
00:05:48,350 --> 00:05:50,110
작가의 플랫폼에 올라오는 글을

178
00:05:50,110 --> 00:05:51,900
모니터링하고, 특정 기준을

179
00:05:51,900 --> 00:05:54,040
통과하는 경우 게시물 링크를

180
00:05:54,040 --> 00:05:56,220
디스코드로 전달하는 기능을 수행합니다.

181
00:05:56,220 --> 00:05:57,890
지금까지는 나의 관심사에

182
00:05:57,890 --> 00:06:00,230
부합하는 콘텐츠를 골라내기 위해

183
00:06:00,230 --> 00:06:03,110
언어 모델에게 콘텐츠 제목만을 제공했습니다.

184
00:06:03,110 --> 00:06:04,650
새로운 게시물의 제목을

185
00:06:04,650 --> 00:06:06,300
언어 모델에게 알려주면서,

186
00:06:06,300 --> 00:06:08,520
"나는 인공지능에 관심이 있는데

187
00:06:08,520 --> 00:06:10,700
이 게시물을 내가 좋아할 것

188
00:06:10,700 --> 00:06:11,810
같아?"라고 물어보는 것이죠.

189
00:06:11,810 --> 00:06:13,590
다시 말해 아직 언어 모델은

190
00:06:13,590 --> 00:06:15,800
콘텐츠 본문을 확인하지 못했습니다.

191
00:06:15,800 --> 00:06:18,480
하지만 이제 우리는 콘텐츠에 대한

192
00:06:18,480 --> 00:06:19,960
또 다른 해석을 만들어보고자

193
00:06:19,960 --> 00:06:22,120
하니까요, 언어 모델이 콘텐츠

194
00:06:22,120 --> 00:06:24,300
원문을 읽을 수 있도록 만들 겁니다.

195
00:06:24,300 --> 00:06:26,850
지난번에는 지나 AI 리더라는 것을

196
00:06:26,850 --> 00:06:28,670
사용해서 스크래핑하는 것을

197
00:06:28,670 --> 00:06:30,540
보여드리면서, 이것이 왜 좋은지

198
00:06:30,540 --> 00:06:32,020
간단히 말씀드렸습니다.

199
00:06:32,020 --> 00:06:33,380
그런데 오늘은 스크래핑이

200
00:06:33,380 --> 00:06:34,390
주제가 아니잖아요.

201
00:06:34,390 --> 00:06:36,310
그래서 그냥 일반적으로 사용되는

202
00:06:36,310 --> 00:06:38,450
방법인 GET 요청을 이용해서,

203
00:06:38,450 --> 00:06:40,760
후보 콘텐츠에 대해 HTML 문서를

204
00:06:40,760 --> 00:06:42,070
가져와 보겠습니다.

205
00:06:42,070 --> 00:06:43,690
이런 결과물이 나왔습니다.

206
00:06:43,690 --> 00:06:45,370
우리는 GPT 노드를 이용해

207
00:06:45,370 --> 00:06:47,740
스크래핑된 결과를 정제할 거예요.

208
00:06:47,740 --> 00:06:49,220
OpenAI의 'Message a Model'

209
00:06:49,220 --> 00:06:51,140
노드를 추가했습니다.

210
00:06:51,140 --> 00:06:53,350
이 노드의 설정을 자세히 살펴볼게요.

211
00:06:53,350 --> 00:06:55,490
우리는 GPT-4-mini 모델을

212
00:06:55,490 --> 00:06:57,190
사용하도록 설정했습니다.

213
00:06:57,190 --> 00:06:58,900
그리고 사용자 프롬프트를

214
00:06:58,900 --> 00:07:00,200
이렇게 작성했어요.

215
00:07:00,200 --> 00:07:03,220
일반적으로, 기나긴 HTML 문서에서

216
00:07:03,220 --> 00:07:05,670
우리는 콘텐츠에만 관심이 있기에

217
00:07:05,670 --> 00:07:08,060
프롬프트를 이렇게 작성해 보았습니다.

218
00:07:08,060 --> 00:07:09,760
자, 이제 화면에 보이는 것은

219
00:07:09,760 --> 00:07:12,310
후처리 전과 후의 결과입니다.

220
00:07:12,310 --> 00:07:14,290
보시다시피, 후처리 전에는

221
00:07:14,290 --> 00:07:16,610
다양한 웹 요소들이 섞여 있었습니다.

222
00:07:16,610 --> 00:07:18,670
반면 후처리 후에는 콘텐츠만

223
00:07:18,670 --> 00:07:20,780
남아있는 것을 확인할 수 있습니다.

224
00:07:20,780 --> 00:07:22,710
다음으로, 우리는 이 정제된

225
00:07:22,710 --> 00:07:24,500
콘텐츠를 저장해야 합니다.

226
00:07:24,500 --> 00:07:26,530
이를 위해 Supabase라는

227
00:07:26,530 --> 00:07:27,950
서비스를 사용할 거예요.

228
00:07:27,950 --> 00:07:29,980
Supabase는 무료로 또는

229
00:07:29,980 --> 00:07:31,800
굉장히 저렴하게 데이터베이스를

230
00:07:31,800 --> 00:07:33,610
사용할 수 있는 서비스입니다.

231
00:07:33,610 --> 00:07:35,640
이런 서비스를 세팅하는 방법은

232
00:07:35,640 --> 00:07:37,770
전체적인 흐름을 설명드리는 데

233
00:07:37,770 --> 00:07:39,140
방해가 되기 때문에,

234
00:07:39,140 --> 00:07:41,010
굉장히 빠르게 넘어갈 것입니다.

235
00:07:41,010 --> 00:07:43,000
앞서 말씀드렸다시피 저희가

236
00:07:43,000 --> 00:07:45,000
해결사 여러분들이 따라하는 데

237
00:07:45,000 --> 00:07:46,870
도움이 되었으면 하는 마음에,

238
00:07:46,870 --> 00:07:49,220
이번에 문서를 엄청 열심히 적어봤어요.

239
00:07:49,220 --> 00:07:52,040
설명이나 댓글에 링크를 걸어두겠습니다.

240
00:07:52,040 --> 00:07:54,080
저희는 Supabase에 콘텐츠를

241
00:07:54,080 --> 00:07:56,290
저장할 저장소를 하나 만들었습니다.

242
00:07:56,290 --> 00:07:57,710
이제 n8n으로 돌아와서,

243
00:07:57,710 --> 00:07:59,600
Supabase의 'Create Row'

244
00:07:59,600 --> 00:08:00,780
노드를 추가합니다.

245
00:08:00,780 --> 00:08:02,110
화면에서 볼 수 있듯이,

246
00:08:02,110 --> 00:08:04,050
이 노드를 통해 우리는 정제된

247
00:08:04,050 --> 00:08:05,620
콘텐츠를 Supabase에

248
00:08:05,620 --> 00:08:07,080
저장할 수 있게 됩니다.

249
00:08:07,080 --> 00:08:09,470
마지막으로, 우리는 저장된 정보의

250
00:08:09,470 --> 00:08:12,340
UUID를 디스코드로 전송합니다.

251
00:08:12,340 --> 00:08:13,730
화면에 보이는 것처럼,

252
00:08:13,730 --> 00:08:15,550
디스코드 노드를 연결하고

253
00:08:15,550 --> 00:08:17,410
메시지 형식을 설정했습니다.

254
00:08:17,410 --> 00:08:18,820
이렇게 하면, 디스코드에

255
00:08:18,820 --> 00:08:21,310
게시물 제목과 링크, 그리고

256
00:08:21,310 --> 00:08:23,060
UUID가 전송됩니다.

257
00:08:23,060 --> 00:08:24,400
자, 이제 전체 워크플로우를

258
00:08:24,400 --> 00:08:25,310
살펴볼까요?

259
00:08:25,310 --> 00:08:26,710
화면에 보이는 것처럼,

260
00:08:26,710 --> 00:08:28,450
우리의 워크플로우는 콘텐츠를

261
00:08:28,450 --> 00:08:30,680
모니터링하고, 스크래핑하고,

262
00:08:30,680 --> 00:08:32,400
정제하고, 저장하고,

263
00:08:32,400 --> 00:08:34,040
마지막으로 디스코드로 알림을

264
00:08:34,040 --> 00:08:36,700
보내는 일련의 과정을 자동화했습니다.

265
00:13:24,990 --> 00:13:26,720
이제 여러 멘토를 추가하여

266
00:13:26,720 --> 00:13:28,250
다양한 조언을 받을 수 있도록

267
00:13:28,250 --> 00:13:29,580
만들어 볼 차례입니다.

268
00:13:29,580 --> 00:13:31,050
피터 틸 뿐만 아니라

269
00:13:31,050 --> 00:13:32,950
스티브 잡스나 일론 머스크 같은

270
00:13:32,950 --> 00:13:34,850
사람들에게도 피드백을 받고 싶은

271
00:13:34,850 --> 00:13:35,460
것이죠.

272
00:13:35,460 --> 00:13:37,330
먼저, 아까 피터 틸의 정보를

273
00:13:37,330 --> 00:13:39,490
작성한 mentors.py 파일에

274
00:13:39,490 --> 00:13:41,600
일론 머스크와 스티브 잡스의

275
00:13:41,600 --> 00:13:42,970
정보를 추가합니다.

276
00:13:42,970 --> 00:13:44,990
그리고 mentor_bot.py에서

277
00:13:44,990 --> 00:13:46,600
프롬프트들을 불러오구요,

278
00:13:46,600 --> 00:13:48,440
멘토 사전을 업데이트합니다.

279
00:13:48,440 --> 00:13:50,210
각각의 멘토들이 어떤 이모지에

280
00:13:50,210 --> 00:13:51,630
반응할지 세팅한다고

281
00:13:51,630 --> 00:13:52,920
생각하면 되겠지요.

282
00:13:52,920 --> 00:13:54,800
이렇게 하면 각 이모지를 통해

283
00:13:54,800 --> 00:13:56,310
원하는 멘토를 선택할 수

284
00:13:56,310 --> 00:13:57,220
있게 됩니다.

285
00:13:57,220 --> 00:13:58,470
한번 확인해 볼까요?

286
00:13:58,470 --> 00:14:01,050
저는 이런 두 개의 프로젝트에 대해

287
00:14:01,050 --> 00:14:03,330
우리가 정의한 세 개의 이모지

288
00:14:03,330 --> 00:14:05,920
모두에 대해 테스트를 진행했습니다.

289
00:14:05,920 --> 00:14:07,430
로켓을 눌렀을 때

290
00:14:07,430 --> 00:14:09,020
일론 머스크가 메시지를 보내고

291
00:14:09,020 --> 00:14:09,640
있구요.

292
00:14:09,640 --> 00:14:11,120
사과를 눌렀을 때

293
00:14:11,120 --> 00:14:13,330
스티브 잡스가 메시지를 보내는 것을

294
00:14:13,330 --> 00:14:14,600
확인할 수 있습니다.

295
00:14:14,600 --> 00:14:16,230
셋의 관점이 미묘하게

296
00:14:16,230 --> 00:14:19,200
실제 인물을 닮아 있는 것 같아서 흥미롭습니다.

297
00:14:19,200 --> 00:14:21,550
아까 잠깐 언급했지만 우리가 멘토로 삼은

298
00:14:21,550 --> 00:14:24,370
피터 틸, 일론 머스크, 스티브 잡스는

299
00:14:24,370 --> 00:14:26,280
영향력이 강한 인물이기 때문에

300
00:14:26,280 --> 00:14:28,050
언어모델이 그들에 대한 정보를

301
00:14:28,050 --> 00:14:29,270
어느 정도 알고 있습니다.

302
00:14:29,270 --> 00:14:32,760
그래서 프롬프트만으로도 그들을 모방하기 충분하죠.

303
00:14:32,760 --> 00:14:34,460
하지만 언어모델이

304
00:14:34,460 --> 00:14:36,720
저나 여러분에 대해 알고 있지는 않겠죠.

305
00:14:36,720 --> 00:14:38,970
그래서 벡터 데이터베이스를 사용하여

306
00:14:38,970 --> 00:14:40,900
나의 지식 기반을 참조하도록

307
00:14:40,900 --> 00:14:42,080
만들어 봅시다.

308
00:14:42,080 --> 00:14:44,950
이렇게 하면 나의 생각과 경험을 바탕으로

309
00:14:44,950 --> 00:14:47,090
프로젝트를 해석할 수 있게 됩니다.

310
00:14:47,090 --> 00:14:49,670
우선 실현 가능성이 있는지 확인하기 위해

311
00:14:49,670 --> 00:14:53,550
피터틸의 저서 제로투원을 벡터 데이터베이스로 만들고

312
00:14:53,550 --> 00:14:55,070
벡터 데이터베이스 기능을 제공하는

313
00:14:55,070 --> 00:14:57,090
서비스들을 사용해보도록 합시다.

314
00:14:57,090 --> 00:15:00,000
우선 최근에 구글에서 출시한 노트북 LM입니다.

315
00:15:00,000 --> 00:15:02,220
이렇게 제로투원 파일을 올려놓고

316
00:15:02,220 --> 00:15:03,560
앞에 사용한 프롬프트와

317
00:15:03,560 --> 00:15:06,390
똑같은 프롬프트를 입력해보도록 하겠습니다.

318
00:15:06,390 --> 00:15:07,560
원문의 많은 부분을

319
00:15:07,560 --> 00:15:09,350
참조한 것을 알 수 있습니다.

320
00:15:09,350 --> 00:15:11,710
처음 나왔을 때에 비해 성능이 많이

321
00:15:11,710 --> 00:15:13,490
좋아졌다는 것이 느껴집니다.

322
00:15:13,490 --> 00:15:16,310
하지만 노트북 LM은 두 가지 문제가 있는데요.

323
00:15:16,310 --> 00:15:17,640
첫 번째 문제는

324
00:15:17,640 --> 00:15:20,750
입력할 수 있는 토큰이 짧은 편이라는 것입니다.

325
00:15:20,750 --> 00:15:23,820
두 번째 문제는 API를 제공하지 않는다는 것입니다.

326
00:15:23,820 --> 00:15:25,930
이들은 앞으로 개선이 되겠지만

327
00:15:25,930 --> 00:15:27,760
지금은 아직 우리의 유즈케이스에

328
00:15:27,760 --> 00:15:30,060
적합하지 않다는 것을 알 수 있습니다.

329
00:15:30,060 --> 00:15:33,190
두 번째는 엔트로픽의 프로젝트 기능입니다.

330
00:15:33,190 --> 00:15:37,030
이번에는 입력 토큰 제한이 비교적 널널한 편이니

331
00:15:37,030 --> 00:15:39,890
토스 창업자 이승건 대표가 과거에 시도했다가

332
00:15:39,890 --> 00:15:42,720
실패했다고 평가하는 모바일 투표 서비스의

333
00:15:42,720 --> 00:15:46,460
인터뷰 내용을 정제해놓고 피드백을 얻어보도록 합시다.

334
00:15:46,460 --> 00:15:49,260
굉장히 문서를 잘 참조해서 답변을 가져오고

335
00:15:49,260 --> 00:15:50,750
저는 개인적으로 답변 품질이

336
00:15:50,750 --> 00:15:52,350
가장 만족스러운 것 같습니다.

337
00:15:52,350 --> 00:15:54,110
실제로 이승건 대표의

338
00:15:54,110 --> 00:15:56,270
과거 창업 시도 내용을 담고 있는

339
00:15:56,270 --> 00:15:58,030
유난한 도전이라는 책에서

340
00:15:58,030 --> 00:16:00,090
이승건 본인이 실패 이후라고

341
00:16:00,090 --> 00:16:01,790
회고하는 것과 동일한 부분을

342
00:16:01,790 --> 00:16:03,610
지적하는 것이 인상 깊습니다.

343
00:16:03,610 --> 00:16:05,850
피터 틸의 글은 잘 되는 것 같은데요.

344
00:16:05,850 --> 00:16:07,950
그렇다면 제가 직접 작성한 글들을

345
00:16:07,950 --> 00:16:09,810
바탕으로 해보는 것은 어떨까요?

346
00:16:09,810 --> 00:16:12,980
제가 스타트업과 관련해서 겪었던 시행착오를

347
00:16:12,980 --> 00:16:15,880
메모한 내용들 중 일부를 이렇게 제공하고

348
00:16:15,880 --> 00:16:17,810
동일한 쿼리를 입력했습니다.

349
00:16:17,810 --> 00:16:20,230
이번 결과물도 상당히 만족스럽습니다.

350
00:16:20,230 --> 00:16:22,800
제 메모를 정말 정확하게 가져와서

351
00:16:22,800 --> 00:16:24,950
훌륭하게 결합했다는 생각이 듭니다.

352
00:16:24,950 --> 00:16:28,390
하지만 아쉽게도 엔트로픽의 프로젝트 기능 또한

353
00:16:28,390 --> 00:16:30,490
비디오를 만드는 시점을 기준으로

354
00:16:30,490 --> 00:16:33,370
API가 제공되지 않아서 사용이 어렵습니다.

355
00:16:33,370 --> 00:16:35,090
마지막으로 사용할 수 있는 것은

356
00:16:35,090 --> 00:16:37,720
오픈 AI의 어시스턴트 API입니다.

357
00:16:37,720 --> 00:16:39,790
어시스턴트를 만드는 방법 또한

358
00:16:39,790 --> 00:16:41,780
문서에 잘 작성해 두었습니다.

359
00:16:41,780 --> 00:16:43,970
설명이나 댓글에 링크를 참고하세요.

360
00:16:43,970 --> 00:16:45,550
화면에 보이는 것처럼

361
00:16:45,550 --> 00:16:48,640
제로 투 원 문서를 지식 베이스로 사용하는

362
00:16:48,640 --> 00:16:51,010
피터틸 어시스턴트를 만들고

363
00:16:51,010 --> 00:16:54,100
계속 사용하고 있는 프롬프트를 입력해보았습니다.

364
00:16:54,100 --> 00:16:56,480
오픈 AI의 경우 상대적으로

365
00:16:56,480 --> 00:16:59,050
노트북 LM이나 클로드 프로젝트에 비해

366
00:16:59,050 --> 00:17:00,840
문서를 잘 활용하지 못했지만

367
00:17:00,840 --> 00:17:03,210
점차 개선이 될 것이라고 생각합니다.

368
00:17:03,210 --> 00:17:06,320
정밀한 개선은 다음 컨텐츠를 위해 남겨두고

369
00:17:06,320 --> 00:17:09,200
내 지식 베이스를 참조한다는 것에 의의를 두고

370
00:17:09,200 --> 00:17:10,950
마무리를 지어보도록 합시다.

371
00:17:10,950 --> 00:17:13,690
제 개인적인 메모들을 지식 베이스로 사용하는

372
00:17:13,690 --> 00:17:15,820
솔브잇 어시스턴트를 만들었습니다.

373
00:17:15,820 --> 00:17:19,540
이제 .env 파일에 assistant ID를 추가합니다.

374
00:17:19,540 --> 00:17:21,500
그리고 멘토 보타 파이에서

375
00:17:21,500 --> 00:17:23,370
assistant ID를 가져옵니다.

376
00:17:23,370 --> 00:17:24,980
assistant를 식별하기 위한

377
00:17:24,980 --> 00:17:27,050
딕셔너리도 이렇게 만들어주고요.

378
00:17:27,050 --> 00:17:30,060
이 코드는 assistant api를 사용하여

379
00:17:30,060 --> 00:17:32,000
멘토의 응답을 생성합니다.

380
00:17:32,000 --> 00:17:33,970
assistant ID가 제공되면

381
00:17:33,970 --> 00:17:35,510
새로운 방식을 사용하고

382
00:17:35,510 --> 00:17:37,840
그렇지 않으면 이전 방식을 사용합니다.

383
00:17:37,840 --> 00:17:39,890
이 함수의 내용도 약간 수정해 줍시다.

384
00:17:39,890 --> 00:17:41,530
어시스턴트가 있는 경우

385
00:17:41,530 --> 00:17:43,270
언어모델 출력을 얻기 위해

386
00:17:43,270 --> 00:17:45,550
멘토 딕셔너리에 들어있는 정보들은

387
00:17:45,550 --> 00:17:46,940
더 이상 필요가 없겠죠.

388
00:17:46,940 --> 00:17:49,470
자 다시 한번 이모지를 붙여보도록 하겠습니다.

389
00:17:49,470 --> 00:17:51,350
저는 블루베리 이모지를 붙이면

390
00:17:51,350 --> 00:17:54,810
솔브잇 어시스턴트가 해석을 제시하기를 기대하고 있죠.

391
00:17:54,810 --> 00:17:56,300
이번에는 운 좋게 문서들을

392
00:17:56,300 --> 00:17:57,630
잘 가져온 것 같네요.

393
00:17:57,630 --> 00:18:00,230
이렇게 제 글에 담긴 생각을 바탕으로

394
00:18:00,230 --> 00:18:01,870
프로젝트를 해석한 결과물을

395
00:18:01,870 --> 00:18:02,950
얻을 수 있습니다.

396
00:18:02,950 --> 00:18:05,050
오늘은 언어모델을 사용해서

397
00:18:05,050 --> 00:18:07,420
정보를 단순히 이해하는 것을 넘어,

398
00:18:07,420 --> 00:18:09,810
해석하는 일에도 사용이 가능하다는

399
00:18:09,810 --> 00:18:12,020
주제로 이야기를 나누어보았습니다.

400
00:18:12,020 --> 00:18:13,890
언어모델을 통해 얻은 해석이

401
00:18:13,890 --> 00:18:15,990
항상 유의미한 것은 아닐 수 있지만,

402
00:18:15,990 --> 00:18:17,930
학계에서도 언어모델을 활용한

403
00:18:17,930 --> 00:18:19,870
다양한 시도가 이루어지고 있습니다.

404
00:18:19,870 --> 00:18:21,800
예를 들어, 연구 주제를

405
00:18:21,800 --> 00:18:23,810
언어모델에게 제안받도록 했는데,

406
00:18:23,810 --> 00:18:25,980
재미있게도 동료 연구자들이

407
00:18:25,980 --> 00:18:28,370
그 아이디어들을 유의미한 수준으로

408
00:18:28,370 --> 00:18:30,720
긍정적 평가를 한 연구 결과도 있지요.

409
00:18:30,720 --> 00:18:32,880
아참 그리고 이번 컨텐츠의 기반이 된

410
00:18:32,880 --> 00:18:35,060
서비스, '찾았다'를 기억하시나요?

411
00:18:35,060 --> 00:18:37,110
저희와 관심사가 비슷한 분들께

412
00:18:37,110 --> 00:18:39,210
뉴스레터를 발송하기 시작했습니다.

413
00:18:39,210 --> 00:18:40,660
한 분 한 분 직접 응대하고

414
00:18:40,660 --> 00:18:42,680
컨텐츠 제작과 병행하다 보니

415
00:18:42,680 --> 00:18:44,150
회신이 많이 늦곤 합니다.

416
00:18:44,150 --> 00:18:46,820
조금 느리더라도 답장은 꼭 드릴 것입니다.

417
00:18:46,820 --> 00:18:49,210
편하게 연락 주시면 감사하겠습니다.

418
00:18:49,210 --> 00:18:51,230
마지막으로 재미있는 이야기를 하고

419
00:18:51,230 --> 00:18:52,870
이야기를 마무리하도록 합시다.

420
00:18:52,870 --> 00:18:54,840
역사를 돌아볼 때, 다른 사람의

421
00:18:54,840 --> 00:18:57,030
해석을 수용해서 재미있는 결과물을

422
00:18:57,030 --> 00:18:59,890
만든 사례를 하나 소개해 주고 싶습니다.

423
00:18:59,890 --> 00:19:02,610
건축계에 루이스 칸이라는 사람이 있습니다.

424
00:19:02,610 --> 00:19:05,060
저도 잘은 모르지만 엄청난 거장이래요.

425
00:19:05,060 --> 00:19:06,940
그 사람의 수많은 걸작 중에서도

426
00:19:06,940 --> 00:19:09,100
두고두고 회자되는 건축물이 있는데요.

427
00:19:09,100 --> 00:19:10,380
바로 이 건축물입니다.

428
00:19:10,380 --> 00:19:13,660
음, 정확히 말하면, 이런 건축물이 '될 뻔' 했습니다.

429
00:19:13,660 --> 00:19:15,530
만약 루이스 바라간이라는 사람의

430
00:19:15,530 --> 00:19:17,320
해석과 조언이 없었다면 말이죠.

431
00:19:17,320 --> 00:19:19,380
"이 공간에 나무나 잔디 대신에

432
00:19:19,380 --> 00:19:21,150
돌로 포장된 중정을 만드십시오.

433
00:19:21,150 --> 00:19:22,960
그러면 입면으로 하늘을

434
00:19:22,960 --> 00:19:24,220
갖게 될 것입니다."

435
00:19:24,220 --> 00:19:26,060
그래서 루이스 칸은 녹지를

436
00:19:26,060 --> 00:19:27,410
다 지워버리고 이런 정원을

437
00:19:27,410 --> 00:19:28,080
만들었죠.

438
00:19:28,080 --> 00:19:29,590
마치 하늘에서 가져온 물감을

439
00:19:29,590 --> 00:19:31,200
땅에 풀어 둔 듯 합니다.

440
00:19:31,200 --> 00:19:33,360
이 결과물은 대자연을 창의적으로

441
00:19:33,360 --> 00:19:35,940
해석한 현대건축으로 회자되고 있습니다.

442
00:19:35,940 --> 00:19:37,580
오늘 소개한 해석 시스템은

443
00:19:37,580 --> 00:19:39,550
아직 발전시킬 부분도 많습니다.

444
00:19:39,550 --> 00:19:42,570
앞서 오픈 AI의 어시스턴트 API는

445
00:19:42,570 --> 00:19:44,370
문서를 가져오는 성능이

446
00:19:44,370 --> 00:19:45,650
들쭉날쭉했습니다.

447
00:19:45,650 --> 00:19:47,210
그럼에도 불구하고 우리는

448
00:19:47,210 --> 00:19:48,560
굉장히 다양한 문제들을

449
00:19:48,560 --> 00:19:49,620
풀어볼 수 있습니다.

450
00:19:49,620 --> 00:19:51,730
여러분들은 오늘 만든 시스템으로

451
00:19:51,730 --> 00:19:53,590
어떤 문제를 풀어보고 싶으신가요?

452
00:19:53,590 --> 00:19:55,080
댓글에 여러분이 이 컨텐츠를

453
00:19:55,080 --> 00:19:57,040
해석한 결과물을 남겨 주세요.

454
00:19:57,040 --> 00:19:58,550
여러분의 해석을 놓고

455
00:19:58,550 --> 00:20:00,610
함께 이야기나눠보고 싶습니다.

456
00:20:00,610 --> 00:20:02,880
여러분의 문제를 IT로 해결한다,

457
00:20:02,880 --> 00:20:04,040
솔브잇이었습니다.
